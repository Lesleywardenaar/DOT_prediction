{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Binance financial data Polkadot\n",
    "In this notebook we will use te 'python-binance' package to extract financial data from Binance' API. For this to work one should have their own Binance account and request an API key and secret password. We are looking to extract financial data from Polkadot from the period between 18-08-2020 (23:00 UTC) to 18-02-2021 (23:59 UTC) with different time frames (1m, 1h, 1d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-binance\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import os.path\n",
    "import time\n",
    "from binance.client import Client\n",
    "from datetime import timedelta, datetime\n",
    "from dateutil import parser\n",
    "\n",
    "\n",
    "### API\n",
    "\n",
    "binance_api_key = '[Enter your own API-key here]'\n",
    "binance_api_secret = '[Enter your own API-secret password here]'\n",
    "\n",
    "### CONSTANTS\n",
    "binsizes = {\"1m\": 1, \"5m\": 5, \"1h\": 60, \"1d\": 1440}\n",
    "batch_size = 750\n",
    "binance_client = Client(api_key=binance_api_key, api_secret=binance_api_secret)\n",
    "\n",
    "\n",
    "### FUNCTIONS\n",
    "def minutes_of_new_data(symbol, kline_size, data, source):\n",
    "    if len(data) > 0:  old = parser.parse(data[\"timestamp\"].iloc[-1])\n",
    "    elif source == \"binance\": old = datetime.strptime('1 Jan 2017', '%d %b %Y')\n",
    "    if source == \"binance\": new = pd.to_datetime(binance_client.get_klines(symbol=symbol, interval=kline_size)[-1][0], unit='ms')\n",
    "    return old, new\n",
    "\n",
    "def get_all_binance(symbol, kline_size, save = False):\n",
    "    filename = '%s-%s-data.csv' % (symbol, kline_size)\n",
    "    if os.path.isfile(filename): data_df = pd.read_csv(filename)\n",
    "    else: data_df = pd.DataFrame()\n",
    "    oldest_point, newest_point = minutes_of_new_data(symbol, kline_size, data_df, source = \"binance\")\n",
    "    delta_min = (newest_point - oldest_point).total_seconds()/60\n",
    "    available_data = math.ceil(delta_min/binsizes[kline_size])\n",
    "    if oldest_point == datetime.strptime('1 Jan 2017', '%d %b %Y'): print('Downloading all available %s data for %s. Be patient..!' % (kline_size, symbol))\n",
    "    else: print('Downloading %d minutes of new data available for %s, i.e. %d instances of %s data.' % (delta_min, symbol, available_data, kline_size))\n",
    "    klines = binance_client.get_historical_klines(symbol, kline_size, oldest_point.strftime(\"%d %b %Y %H:%M:%S\"), newest_point.strftime(\"%d %b %Y %H:%M:%S\"))\n",
    "    data = pd.DataFrame(klines, columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_av', 'trades', 'tb_base_av', 'tb_quote_av', 'ignore' ])\n",
    "    data['timestamp'] = pd.to_datetime(data['timestamp'], unit='ms')\n",
    "    if len(data_df) > 0:\n",
    "        temp_df = pd.DataFrame(data)\n",
    "        data_df = data_df.append(temp_df)\n",
    "    else: data_df = data\n",
    "    data_df.set_index('timestamp', inplace=True)\n",
    "    if save: data_df.to_csv(filename)\n",
    "    print('All caught up..!')\n",
    "    return data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 27096 minutes of new data available for DOTUSDT, i.e. 27096 instances of 1m data.\n",
      "All caught up..!\n",
      "Downloading 27060 minutes of new data available for DOTUSDT, i.e. 451 instances of 1h data.\n",
      "All caught up..!\n",
      "Downloading 27360 minutes of new data available for DOTUSDT, i.e. 19 instances of 1d data.\n",
      "All caught up..!\n"
     ]
    }
   ],
   "source": [
    "DOTUSDT_1m = get_all_binance('DOTUSDT', \"1m\", save = True )\n",
    "DOTUSDT_1h = get_all_binance('DOTUSDT', \"1h\", save = True )\n",
    "DOTUSDT_1d = get_all_binance('DOTUSDT', \"1d\", save = True )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After manually inspecting the datasets it became clear that there is data missing in the 1m and 1h dataset on 30/11/2020, 21/12/2020 and 11/02/2021. The missing data corresponds with announced maintenance. Therefore all missing timeframes are manually inserted with 0 trading volume etc. and a non-changing start, high, low, end prices. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
